{"paragraphs":[{"text":"%md\n## Solutions of exercises week-5\n\nImportant notes - the solutions of this week's exercices use a fictional user id `gaspar`. Before experimenting, you should change all references to `gaspar` in this notebook with your own user id.","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>Solutions of exercises week-5</h2>\n<p>Important notes - the solutions of this week's exercices use a fictional user id <code>gaspar</code>. Before experimenting, you should change all references to <code>gaspar</code> in this notebook with your own user id.</p>\n"}]},"apps":[],"jobName":"paragraph_1553669999427_-645816014","id":"20190325-221546_26260481","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:45956"},{"text":"%md\n### First steps with HDFS\n\nLogin to the IC cluster with your __gaspar__ login name and password.\n\n```shell\nssh your_gaspar_name@iccluster042.iccluster.epfl.ch\n```\n\nOnce logged on the cluster, you can get started with the HDFS command line interface with\n\n```shell\nhdfs dfs\n```\n\nThe output is the list of HDFS file system actions available via the hdfs command line. Notice how most of the commands behave like the familiar Linux file system commands.\n\nAs a first exercise, you will explore the content of the cluster's HDFS file system using the __hdfs dfs__ command.\n\n1. We have created a directory on HDFS for each of you, can you find yours?\n2. Create a folder __work1__ in your HDFS directory and change the access rights of your directory so that only you and the hadoop group can read and write into it.\n3. Copy the 2017 _Traffic Count_ data published by the [Calderdale Metropolitan Borough Council (UK)](https://data.gov.uk/dataset/0c64970c-756a-46b2-9282-4a62016c7c64/traffic-count) to your __work1__ directory. A copy of the data is available from the [dslab 2019 github repository](https://github.com/dslab2019/dslab2019.github.io/blob/master/data/week5/01012017_to_31072017.csv.bz2?raw=true)\n\nHints: (1) use the __scp__ or the __wget__ commands to copy the data locally in your home directory, and one of the __hdfs dfs__ commands to copy the local file to your HDFS directory, (2) HDFS does not like spaces in filenames.\n","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>First steps with HDFS</h3>\n<p>Login to the IC cluster with your <strong>gaspar</strong> login name and password.</p>\n<pre><code class=\"shell\">ssh your_gaspar_name@iccluster042.iccluster.epfl.ch\n</code></pre>\n<p>Once logged on the cluster, you can get started with the HDFS command line interface with</p>\n<pre><code class=\"shell\">hdfs dfs\n</code></pre>\n<p>The output is the list of HDFS file system actions available via the hdfs command line. Notice how most of the commands behave like the familiar Linux file system commands.</p>\n<p>As a first exercise, you will explore the content of the cluster's HDFS file system using the <strong>hdfs dfs</strong> command.</p>\n<ol>\n<li>We have created a directory on HDFS for each of you, can you find yours?</li>\n<li>Create a folder <strong>work1</strong> in your HDFS directory and change the access rights of your directory so that only you and the hadoop group can read and write into it.</li>\n<li>Copy the 2017 <em>Traffic Count</em> data published by the <a href=\"https://data.gov.uk/dataset/0c64970c-756a-46b2-9282-4a62016c7c64/traffic-count\">Calderdale Metropolitan Borough Council (UK)</a> to your <strong>work1</strong> directory. A copy of the data is available from the <a href=\"https://github.com/dslab2019/dslab2019.github.io/blob/master/data/week5/01012017_to_31072017.csv.bz2?raw=true\">dslab 2019 github repository</a></li>\n</ol>\n<p>Hints: (1) use the <strong>scp</strong> or the <strong>wget</strong> commands to copy the data locally in your home directory, and one of the <strong>hdfs dfs</strong> commands to copy the local file to your HDFS directory, (2) HDFS does not like spaces in filenames.</p>\n"}]},"apps":[],"jobName":"paragraph_1553669999429_2095167392","id":"20190320-015847_1939308302","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45957"},{"text":"%md\n### First steps with Hive\n\nCreate your database on hive. We will name it with your EPFL gaspar name.\n\n```shell\n%jdbc(hive)\ncreate database if not exists your_gaspar_name\n  location '/homes/your_gaspar_name/hive'; \n```\n\nCreate an external Hive table. Hive will create a reference to the files but it will not manage the files itself. If you drop the table, only the definition in Hive is deleted. This exercise will work only if you have completed the HDFS exercises.\n\n```shell\n%jdbc(hive)\ncreate external table if not exists your_gaspar_name.traffic_count(Sdate string,Cosit int,Study int,Period int,LaneNumber int,LaneDescription string,LaneDirection int,DirectionDescription string,Volume int,Flags int,FlagText string,Setup int,NumBins int,Bins int)\n    row format delimited fields terminated by ','\n    stored as textfile\n    location '/homes/your_gaspar_name/work1/';\n```\n\nNow verify that your table was properly created.\n```shell\n%jdbc(hive)\nselect * from your_gaspar_name.traffic_count limit 10;\n```\n\nReplace your_gaspar_name with your username and try the above commands in the next cells, create as many cells as needed.\n\nNote the first row. what did we do wrong?\n","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"editOnDblClick":true,"language":"markdown","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>First steps with Hive</h3>\n<p>Create your database on hive. We will name it with your EPFL gaspar name.</p>\n<pre><code class=\"shell\">%jdbc(hive)\ncreate database if not exists your_gaspar_name\n  location '/homes/your_gaspar_name/hive'; \n</code></pre>\n<p>Create an external Hive table. Hive will create a reference to the files but it will not manage the files itself. If you drop the table, only the definition in Hive is deleted. This exercise will work only if you have completed the HDFS exercises.</p>\n<pre><code class=\"shell\">%jdbc(hive)\ncreate external table if not exists your_gaspar_name.traffic_count(Sdate string,Cosit int,Study int,Period int,LaneNumber int,LaneDescription string,LaneDirection int,DirectionDescription string,Volume int,Flags int,FlagText string,Setup int,NumBins int,Bins int)\n    row format delimited fields terminated by ','\n    stored as textfile\n    location '/homes/your_gaspar_name/work1/';\n</code></pre>\n<p>Now verify that your table was properly created.</p>\n<pre><code class=\"shell\">%jdbc(hive)\nselect * from your_gaspar_name.traffic_count limit 10;\n</code></pre>\n<p>Replace your_gaspar_name with your username and try the above commands in the next cells, create as many cells as needed.</p>\n<p>Note the first row. what did we do wrong?</p>\n"}]},"apps":[],"jobName":"paragraph_1553669999430_-1952028710","id":"20180320-102737_103167059","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45958"},{"text":"%jdbc(hive)\ncreate database if not exists gaspar\n  location '/homes/gaspar/hive'; \n  \ndrop table if exists gaspar.traffic_count;\n\ncreate external table if not exists gaspar.traffic_count(Sdate string,Cosit int,Study int,Period int,LaneNumber int,LaneDescription string,LaneDirection int,DirectionDescription string,Volume int,Flags int,FlagText string,Setup int,NumBins int,Bins int)\n    row format delimited fields terminated by ','\n    stored as textfile\n    location '/homes/gaspar/work1/';\n    \nselect * from gaspar.traffic_count limit 10;\n\n","user":"ebouille","dateUpdated":"2019-03-27T08:08:27+0100","config":{"tableHide":false,"editorSetting":{"editOnDblClick":false,"language":"sql","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"editorHide":false,"results":{"2":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"traffic_count.sdate":"string","traffic_count.cosit":"string","traffic_count.study":"string","traffic_count.period":"string","traffic_count.lanenumber":"string","traffic_count.lanedescription":"string","traffic_count.lanedirection":"string","traffic_count.directiondescription":"string","traffic_count.volume":"string","traffic_count.flags":"string","traffic_count.flagtext":"string","traffic_count.setup":"string","traffic_count.numbins":"string","traffic_count.bins":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}},"3":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"traffic_count.sdate":"string","traffic_count.cosit":"string","traffic_count.study":"string","traffic_count.period":"string","traffic_count.lanenumber":"string","traffic_count.lanedescription":"string","traffic_count.lanedirection":"string","traffic_count.directiondescription":"string","traffic_count.volume":"string","traffic_count.flags":"string","traffic_count.flagtext":"string","traffic_count.setup":"string","traffic_count.numbins":"string","traffic_count.bins":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1553669999431_-253355164","id":"20180321-025846_71567959","dateCreated":"2019-03-27T07:59:59+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:45959","dateFinished":"2019-03-27T08:07:36+0100","dateStarted":"2019-03-27T08:07:35+0100","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TABLE","data":"traffic_count.sdate\ttraffic_count.cosit\ttraffic_count.study\ttraffic_count.period\ttraffic_count.lanenumber\ttraffic_count.lanedescription\ttraffic_count.lanedirection\ttraffic_count.directiondescription\ttraffic_count.volume\ttraffic_count.flags\ttraffic_count.flagtext\ttraffic_count.setup\ttraffic_count.numbins\ttraffic_count.bins\nSdate\tnull\tnull\tnull\tnull\tLaneDescription\tnull\tDirectionDescription\tnull\tnull\tFlag Text\tnull\tnull\tnull\n24/07/2017 11:00\t70301\t1\t60\t1\tNorthbound\t1\tNorthEast\t-1\t10496\t\"Estimate\tnull\tnull\t1\n24/07/2017 11:00\t70301\t1\t60\t2\tSouthbound\t2\tSouthWest\t-1\t10496\t\"Estimate\tnull\tnull\t1\n24/07/2017 12:00\t70301\t1\t60\t1\tNorthbound\t1\tNorthEast\t92\t8192\tChecked\t1\t0\tnull\n24/07/2017 12:00\t70301\t1\t60\t2\tSouthbound\t2\tSouthWest\t67\t8192\tChecked\t1\t0\tnull\n24/07/2017 13:00\t70301\t1\t60\t1\tNorthbound\t1\tNorthEast\t89\t8192\tChecked\t1\t0\tnull\n24/07/2017 13:00\t70301\t1\t60\t2\tSouthbound\t2\tSouthWest\t94\t8192\tChecked\t1\t0\tnull\n24/07/2017 14:00\t70301\t1\t60\t1\tNorthbound\t1\tNorthEast\t105\t8192\tChecked\t1\t0\tnull\n24/07/2017 14:00\t70301\t1\t60\t2\tSouthbound\t2\tSouthWest\t64\t8192\tChecked\t1\t0\tnull\n24/07/2017 15:00\t70301\t1\t60\t1\tNorthbound\t1\tNorthEast\t107\t8192\tChecked\t1\t0\tnull\n"}]}},{"text":"%md\n#### Answer\nNote the mistake: the first row is the header of the table, we should ignore it when we create the table as follows:\n```shell\n%jdbc(hive)\ncreate external table if not exists gaspar.traffic_count(Sdate string,Cosit int,Study int,Period int,LaneNumber int,LaneDescription string,LaneDirection int,DirectionDescription string,Volume int,Flags int,FlagText string,Setup int,NumBins int,Bins int)\n    row format delimited fields terminated by ','\n    stored as textfile\n    location '/homes/gaspar/work1/'\n    tblproperties (\"skip.header.line.count\"=\"1\");\n```\n","user":"ebouille","dateUpdated":"2019-03-27T08:08:55+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Answer</h4>\n<p>Note the mistake: the first row is the header of the table, we should ignore it when we create the table as follows:</p>\n<pre><code class=\"shell\">%jdbc(hive)\ncreate external table if not exists gaspar.traffic_count(Sdate string,Cosit int,Study int,Period int,LaneNumber int,LaneDescription string,LaneDirection int,DirectionDescription string,Volume int,Flags int,FlagText string,Setup int,NumBins int,Bins int)\n    row format delimited fields terminated by ','\n    stored as textfile\n    location '/homes/gaspar/work1/'\n    tblproperties (\"skip.header.line.count\"=\"1\");\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1553669999431_-1877240773","id":"20190327-073710_797950202","dateCreated":"2019-03-27T07:59:59+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:45960","dateFinished":"2019-03-27T08:08:55+0100","dateStarted":"2019-03-27T08:08:55+0100"},{"text":"%md\n#### Notes\n\nThe `create database` creates what is called a __metastore__. A metastore contains all the information that hive needs to know to operate on your database. This information includes the table schemas, their locations, and how they are partitioned on the cluster. This metastore is stored as files in the __hdfs__ `/homes/your_gaspar_name/hive` directory, as specified by the `location` argument. You can check the content of this folder with the `hdfs dfs -ls` command. The hdfs directory must be __rwx__-accessible to the hadoop group (with the `hdfs dfs -chmod` command), so that the hive engine (which is part of the hadoop group) can creates those files into your directory. Unfortunately, this means that others can access the database via any services of the hadoop group. If the argument `location` is not specified, __hive__ stores the file in a default location. This location is owned by hive and is a little bit more restrictive, but is it is still accessible by anyone who can run a hive command. In a normal setting, we would use solutions like __ranger__, which allows the expression of finer-grained access controls. The take-home message is that access control in a big data ecosystem can be challenging.\n\nThe `create table` command creates a new table. The meta data of this table, such as schema description, is stored in in the database's __metastore__. We declare the table `external`, meaning that it is just a reference to the orignal CSV data stored in `work1`. Droping the table will delete the meta data corresponding to the table in the hive metastore. It will not delete the original data that it maps to.\n","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Notes</h4>\n<p>The <code>create database</code> creates what is called a <strong>metastore</strong>. A metastore contains all the information that hive needs to know to operate on your database. This information includes the table schemas, their locations, and how they are partitioned on the cluster. This metastore is stored as files in the <strong>hdfs</strong> <code>/homes/your_gaspar_name/hive</code> directory, as specified by the <code>location</code> argument. You can check the content of this folder with the <code>hdfs dfs -ls</code> command. The hdfs directory must be <strong>rwx</strong>-accessible to the hadoop group (with the <code>hdfs dfs -chmod</code> command), so that the hive engine (which is part of the hadoop group) can creates those files into your directory. Unfortunately, this means that others can access the database via any services of the hadoop group. If the argument <code>location</code> is not specified, <strong>hive</strong> stores the file in a default location. This location is owned by hive and is a little bit more restrictive, but is it is still accessible by anyone who can run a hive command. In a normal setting, we would use solutions like <strong>ranger</strong>, which allows the expression of finer-grained access controls. The take-home message is that access control in a big data ecosystem can be challenging.</p>\n<p>The <code>create table</code> command creates a new table. The meta data of this table, such as schema description, is stored in in the database's <strong>metastore</strong>. We declare the table <code>external</code>, meaning that it is just a reference to the orignal CSV data stored in <code>work1</code>. Droping the table will delete the meta data corresponding to the table in the hive metastore. It will not delete the original data that it maps to.</p>\n"}]},"apps":[],"jobName":"paragraph_1553669999432_-776113887","id":"20190325-205120_1066051596","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45961"},{"text":"%md\n### Import one day of Twitter data into Hive\n\nCreate an external table  from HDFS dir __/datasets/twitter_one_day__ and call it __your_gaspar_name.twitter_one_day__. The table should have a single column named __json__ of type __string__. Do not forget to use your own database (gaspar name)!\n\nA few hints:\n(1) You can explore the __/datasets/twitter_one_day__ directory from your terminal with the __hdfs dfs -ls__ command. You will notice that the files are in bzip2 format. Do not worry about that, Hive knows how to handle compressed text files automatically.\n(2) The files have only one field per line\n(3) If you do not specify the row format, the default format __fields terminated by '\\n'__ will be used.\n\nAfter the table __twitter_one_day__ is created, verify the content of its first row with a select command (limit 1). Use the output of the select query to identify the json fields where the the language and the timestamp information of the tweet are stored. You can use [__http://jsonprettyprint.com/__](http://jsonprettyprint.com/) to pretty print the json string.\n\n","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"editOnDblClick":true,"language":"markdown","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Import one day of Twitter data into Hive</h3>\n<p>Create an external table  from HDFS dir <strong>/datasets/twitter_one_day</strong> and call it <strong>your_gaspar_name.twitter_one_day</strong>. The table should have a single column named <strong>json</strong> of type <strong>string</strong>. Do not forget to use your own database (gaspar name)!</p>\n<p>A few hints:\n<br  />(1) You can explore the <strong>/datasets/twitter_one_day</strong> directory from your terminal with the <strong>hdfs dfs -ls</strong> command. You will notice that the files are in bzip2 format. Do not worry about that, Hive knows how to handle compressed text files automatically.\n<br  />(2) The files have only one field per line\n<br  />(3) If you do not specify the row format, the default format <strong>fields terminated by '\\n'</strong> will be used.</p>\n<p>After the table <strong>twitter_one_day</strong> is created, verify the content of its first row with a select command (limit 1). Use the output of the select query to identify the json fields where the the language and the timestamp information of the tweet are stored. You can use <a href=\"http://jsonprettyprint.com/\"><strong>http://jsonprettyprint.com/</strong></a> to pretty print the json string.</p>\n"}]},"apps":[],"jobName":"paragraph_1553669999433_-284179150","id":"20180320-133148_586015451","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45962"},{"text":"%jdbc(hive)\ncreate external table if not exists gaspar.twitter_one_day(json string)\n  stored as parquet\n  location '/homes/gaspar/hive'; \n","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"editOnDblClick":false,"language":"sql","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{"1":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"lang":"string","count":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"}]},"apps":[],"jobName":"paragraph_1553669999434_326083877","id":"20180321-030249_154474664","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45963"},{"text":"%jdbc(hive)\nselect * from gaspar.twitter_one_day limit 1;","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"editorSetting":{"language":"sql","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":304.933,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"twitter_one_day.json":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"twitter_one_day.json","index":0,"aggr":"sum"}],"groups":[],"values":[]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"twitter_one_day.json\n{\"created_at\":\"Wed Oct 31 06:29:00 +0000 2018\",\"id\":1057519791269912579,\"id_str\":\"1057519791269912579\",\"text\":\"I'm talking clearly to myself right now.\",\"source\":\"\\u003ca href=\\\"http:\\/\\/twitter.com\\/download\\/android\\\" rel=\\\"nofollow\\\"\\u003eTwitter for Android\\u003c\\/a\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":null,\"in_reply_to_status_id_str\":null,\"in_reply_to_user_id\":null,\"in_reply_to_user_id_str\":null,\"in_reply_to_screen_name\":null,\"user\":{\"id\":430723859,\"id_str\":\"430723859\",\"name\":\"Esraa\",\"screen_name\":\"Esraasalah12\",\"location\":\"Egypt\",\"url\":null,\"description\":\"NO !\",\"translator_type\":\"none\",\"protected\":false,\"verified\":false,\"followers_count\":568,\"friends_count\":279,\"listed_count\":6,\"favourites_count\":836,\"statuses_count\":17650,\"created_at\":\"Wed Dec 07 14:05:35 +0000 2011\",\"utc_offset\":null,\"time_zone\":null,\"geo_enabled\":true,\"lang\":\"en\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"642D8B\",\"profile_background_image_url\":\"http:\\/\\/abs.twimg.com\\/images\\/themes\\/theme10\\/bg.gif\",\"profile_background_image_url_https\":\"https:\\/\\/abs.twimg.com\\/images\\/themes\\/theme10\\/bg.gif\",\"profile_background_tile\":true,\"profile_link_color\":\"981CEB\",\"profile_sidebar_border_color\":\"000000\",\"profile_sidebar_fill_color\":\"7AC3EE\",\"profile_text_color\":\"3D1957\",\"profile_use_background_image\":true,\"profile_image_url\":\"http:\\/\\/pbs.twimg.com\\/profile_images\\/879168974960959492\\/gzrBLGnH_normal.jpg\",\"profile_image_url_https\":\"https:\\/\\/pbs.twimg.com\\/profile_images\\/879168974960959492\\/gzrBLGnH_normal.jpg\",\"profile_banner_url\":\"https:\\/\\/pbs.twimg.com\\/profile_banners\\/430723859\\/1411242800\",\"default_profile\":false,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\"place\":{\"id\":\"01accfd07cdf862b\",\"url\":\"https:\\/\\/api.twitter.com\\/1.1\\/geo\\/id\\/01accfd07cdf862b.json\",\"place_type\":\"admin\",\"name\":\"Alexandria\",\"full_name\":\"Alexandria, Egypt\",\"country_code\":\"EG\",\"country\":\"Egypt\",\"bounding_box\":{\"type\":\"Polygon\",\"coordinates\":[[[29.380810,30.333034],[29.380810,31.332279],[30.086218,31.332279],[30.086218,30.333034]]]},\"attributes\":{}},\"contributors\":null,\"is_quote_status\":false,\"quote_count\":0,\"reply_count\":0,\"retweet_count\":0,\"favorite_count\":0,\"entities\":{\"hashtags\":[],\"urls\":[],\"user_mentions\":[],\"symbols\":[]},\"favorited\":false,\"retweeted\":false,\"filter_level\":\"low\",\"lang\":\"en\",\"timestamp_ms\":\"1540967340663\"}\n"}]},"apps":[],"jobName":"paragraph_1553669999435_287339625","id":"20190325-185433_76652918","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45964"},{"text":"%md\n### Twitter language frequency\n\nCompute the language frequencies, sorted in decreasing order of popularity. You should only use standard SQL group and count commands.\n\nTake advantage of the Zeppelin graph toolbar that appears with the results.\n\n```shell\n%jdbc(hive)\nwith q as (\n    select\n        get_json_object(json, '$.lang') as lang\n    from CHANGEME.twitter_one_day\n)\n\nselect lang, count(*) as count\nfrom q\ngroup by lang\norder by count desc;\n```\n\nYou can try different visualizations of the results with the embedded Zeppelin graph interface.\n\nFor further reading see the distinction between __group by__ and __sort by__ in __https://cwiki.apache.org/confluence/display/Hive/LanguageManual+SortBy__ . You can try this at home.\n","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"editOnDblClick":true,"language":"markdown","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{"0":{"graph":{"mode":"pieChart","height":300,"optionOpen":true,"setting":{"multiBarChart":{"stacked":false}},"commonSetting":{},"keys":[{"name":"lang","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Twitter language frequency</h3>\n<p>Compute the language frequencies, sorted in decreasing order of popularity. You should only use standard SQL group and count commands.</p>\n<p>Take advantage of the Zeppelin graph toolbar that appears with the results.</p>\n<pre><code class=\"shell\">%jdbc(hive)\nwith q as (\n    select\n        get_json_object(json, '$.lang') as lang\n    from CHANGEME.twitter_one_day\n)\n\nselect lang, count(*) as count\nfrom q\ngroup by lang\norder by count desc;\n</code></pre>\n<p>You can try different visualizations of the results with the embedded Zeppelin graph interface.</p>\n<p>For further reading see the distinction between <strong>group by</strong> and <strong>sort by</strong> in <strong>https://cwiki.apache.org/confluence/display/Hive/LanguageManual+SortBy</strong> . You can try this at home.</p>\n"}]},"apps":[],"jobName":"paragraph_1553669999435_1682351684","id":"20180320-135324_2117720219","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45965"},{"text":"%jdbc(hive)\nwith q as (\n    select\n        get_json_object(json, '$.lang') as lang\n    from gaspar.twitter_one_day\n)\n\nselect lang, count(*) as count\nfrom q\ngroup by lang\norder by count desc;","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{"0":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"lang":"string","count":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false},"multiBarChart":{"rotate":{"degree":"-45"},"xLabelStatus":"default"}},"commonSetting":{},"keys":[{"name":"lang","index":0,"aggr":"sum"}],"groups":[],"values":[{"name":"count","index":1,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"lang\tcount\nnull\t1093927\nen\t1000592\nja\t595280\nes\t261621\nund\t215632\npt\t206518\nar\t184436\nko\t181185\nth\t149236\nin\t74763\nfr\t60850\ntl\t56007\ntr\t52535\nru\t18026\nit\t16864\nhi\t16382\nde\t11602\nur\t9809\nfa\t7580\nnl\t7455\npl\t7072\nca\t5482\net\t4365\nht\t4338\nzh\t4195\nel\t3138\nta\t2619\nsv\t2589\nfi\t1677\ncs\t1411\neu\t1325\nda\t1245\ncy\t1207\nno\t1204\nvi\t1148\nro\t1101\nuk\t1033\nhu\t1008\nsr\t781\nlt\t769\nne\t764\niw\t753\nlv\t674\nte\t500\nsl\t458\nis\t426\nmr\t384\nbn\t383\nkn\t334\nbg\t308\nml\t302\nmy\t187\ngu\t110\nsi\t96\nhy\t48\nckb\t44\nps\t42\nor\t36\npa\t35\nam\t25\nka\t23\nsd\t22\nkm\t18\ndv\t8\nlo\t7\nbo\t1\n"}]},"apps":[],"jobName":"paragraph_1553669999436_-473592709","id":"20180321-042338_1447379256","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45966"},{"text":"%md\n### Extract the timeseries of languages used in twitter.\n\nIn this exercise, you will only keep the language and timestamp information (in ms since 01.01.1971 00:00:00 +00:00) of each tweet from the __twitter_one_day__ table. The result will be a table with a column __lang__ of type string and a column __time__ of type timestamp. You will store this result into a new table called __twitter_lang__.\n\nWe provide part of the query. You must fix all CHANGEME as needed in order to perform the above operation. Use the drop table command if you do not get the table right the first time.\n\n```shell\n%jdbc(hive)\n\ncreate table CHANGEME\nstored as parquet\nas\nselect\n    get_json_object(json, CHANGEME) as CHANGEME,\n    from_utc_timestamp(cast(CHANGEME as bigint), 'UTC') as CHANGEME\nfrom CHANGEME;\n```\n\n","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"editOnDblClick":true,"language":"markdown","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Extract the timeseries of languages used in twitter.</h3>\n<p>In this exercise, you will only keep the language and timestamp information (in ms since 01.01.1971 00:00:00 +00:00) of each tweet from the <strong>twitter_one_day</strong> table. The result will be a table with a column <strong>lang</strong> of type string and a column <strong>time</strong> of type timestamp. You will store this result into a new table called <strong>twitter_lang</strong>.</p>\n<p>We provide part of the query. You must fix all CHANGEME as needed in order to perform the above operation. Use the drop table command if you do not get the table right the first time.</p>\n<pre><code class=\"shell\">%jdbc(hive)\n\ncreate table CHANGEME\nstored as parquet\nas\nselect\n    get_json_object(json, CHANGEME) as CHANGEME,\n    from_utc_timestamp(cast(CHANGEME as bigint), 'UTC') as CHANGEME\nfrom CHANGEME;\n</code></pre>\n"}]},"apps":[],"jobName":"paragraph_1553669999437_-153566120","id":"20180320-134103_2004356345","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45967"},{"text":"%jdbc(hive)\n\ndrop table if exists gaspar.twitter_lang ;\ncreate table gaspar.twitter_lang\nstored as parquet\nas\nselect\n    get_json_object(json, '$.lang') as lang,\n    from_utc_timestamp(from_unixtime(cast(cast(get_json_object(json, '$.timestamp_ms') as bigint)/1000 as bigint)), 'UTC') as time_str\nfrom gaspar.twitter_one_day;\n\nselect * from gaspar.twitter_lang limit 1;","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{"2":{"graph":{"mode":"table","height":300,"optionOpen":false,"setting":{"table":{"tableGridState":{},"tableColumnTypeState":{"names":{"twitter_lang.lang":"string","twitter_lang.time_str":"string"},"updated":false},"tableOptionSpecHash":"[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]","tableOptionValue":{"useFilter":false,"showPagination":false,"showAggregationFooter":false},"updated":false,"initialized":false}},"commonSetting":{}}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TABLE","data":"twitter_lang.lang\ttwitter_lang.time_str\nen\t2018-10-31 15:00:00.0\n"}]},"apps":[],"jobName":"paragraph_1553669999438_1880000610","id":"20180321-042426_1858484630","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45968"},{"text":"%md\n### The mysterious Hive query\n\nCan you guess the meaning of this Hive command?\n\n```shell\n%jdbc(hive)\ncreate table CHANGEME.twitter_lang_csv\nrow format delimited\n    fields terminated by ','\n    escaped by '\"'\n    lines terminated by '\\n'\nstored as textfile\nas\nwith q as (\n    select \n        lang,\n        cast(date_format(time, 'HH') as int) as hour\n    from CHANGEME\n)\nselect lang, hour, count(*) as count\nfrom q\ngroup by lang, hour;\n```\n\nReplace all CHANGME occurences as appropriate and try it.","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"editOnDblClick":true,"language":"markdown","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>The mysterious Hive query</h3>\n<p>Can you guess the meaning of this Hive command?</p>\n<pre><code class=\"shell\">%jdbc(hive)\ncreate table CHANGEME.twitter_lang_csv\nrow format delimited\n    fields terminated by ','\n    escaped by '\"'\n    lines terminated by '\\n'\nstored as textfile\nas\nwith q as (\n    select \n        lang,\n        cast(date_format(time, 'HH') as int) as hour\n    from CHANGEME\n)\nselect lang, hour, count(*) as count\nfrom q\ngroup by lang, hour;\n</code></pre>\n<p>Replace all CHANGME occurences as appropriate and try it.</p>\n"}]},"apps":[],"jobName":"paragraph_1553669999439_1635906533","id":"20180320-135452_2072033476","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45969"},{"text":"%md\n#### Answer\n\nThis query create a new table `twitter_lang_csv`, which contains the aggregated count of of each language for each hour of the day. The table is stored in human readable csv format in the `/homes/your_gaspar_name/hive/twitter_lang_csv` folder.\n\nYou can check the content of the table by opening a terminal on `iccluster042.iccluster.epfl.ch`, create a folder `~/tmp` in your home directory, and run the command `hdfs dfs -copyToLocal /homes/your_gaspar_name/hive/twitter_lang_csv ~/tmp`.\n\nNote that we use the CSV format because the table is small. However it is not very efficient. It should be avoided for larger data sets.","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h4>Answer</h4>\n<p>This query create a new table <code>twitter_lang_csv</code>, which contains the aggregated count of of each language for each hour of the day. The table is stored in human readable csv format in the <code>/homes/your_gaspar_name/hive/twitter_lang_csv</code> folder.</p>\n<p>You can check the content of the table by opening a terminal on <code>iccluster042.iccluster.epfl.ch</code>, create a folder <code>~/tmp</code> in your home directory, and run the command <code>hdfs dfs -copyToLocal /homes/your_gaspar_name/hive/twitter_lang_csv ~/tmp</code>.</p>\n<p>Note that we use the CSV format because the table is small. However it is not very efficient. It should be avoided for larger data sets.</p>\n"}]},"apps":[],"jobName":"paragraph_1553669999439_86020250","id":"20190325-203854_1610596702","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45970"},{"text":"%jdbc(hive)\ndrop table if exists gaspar.twitter_lang_csv ;\ncreate table gaspar.twitter_lang_csv\nrow format delimited\n    fields terminated by ','\n    escaped by '\"'\n    lines terminated by '\\n'\n    stored as textfile\nas\nwith q as (\n    select \n        lang,\n        cast(date_format(time_str, 'HH') as int) as hour\n    from gaspar.twitter_lang\n)\nselect lang, hour, count(*) as count\nfrom q\ngroup by lang, hour;","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"},{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"}]},"apps":[],"jobName":"paragraph_1553669999440_-678412291","id":"20180321-093624_789131470","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45971"},{"text":"%md\n### Display language frequencies at different times of the day\n\nIn the next query you will display the frequecny tweets in Portuguese (pt) and Korean (ko) for each hour of the day.\n\nHints: (1) Only keep the tweets where the hour is not null and the lang is in ('pt', 'ko'), (2) use the SQL __where__ clause.\n\nSelect the bar chart view in Zeppelin graph toolbar that appears with the result. Then the open the settings and arrange the output fields (drag and drop) in the keys, groups and values properties until you get an insightful plot.\n\n\n","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"editOnDblClick":true,"language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Display language frequencies at different times of the day</h3>\n<p>In the next query you will display the frequecny tweets in Portuguese (pt) and Korean (ko) for each hour of the day.</p>\n<p>Hints: (1) Only keep the tweets where the hour is not null and the lang is in ('pt', 'ko'), (2) use the SQL <strong>where</strong> clause.</p>\n<p>Select the bar chart view in Zeppelin graph toolbar that appears with the result. Then the open the settings and arrange the output fields (drag and drop) in the keys, groups and values properties until you get an insightful plot.</p>\n"}]},"apps":[],"jobName":"paragraph_1553669999441_-1219386636","id":"20180321-094259_347812219","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45972"},{"text":"%jdbc(hive)\nselect * from gaspar.twitter_lang_csv where hour is not null and (lang='pt' or lang='ko');\n\n","user":"ebouille","dateUpdated":"2019-03-27T08:00:08+0100","config":{"tableHide":false,"editorSetting":{"editOnDblClick":false,"language":"sql","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","editorHide":false,"fontSize":9,"results":{"0":{"graph":{"mode":"multiBarChart","height":300,"optionOpen":false,"setting":{"multiBarChart":{"stacked":false,"rotate":{"degree":"-45"},"xLabelStatus":"default"},"pieChart":{},"stackedAreaChart":{"style":"stream"}},"commonSetting":{},"keys":[{"name":"twitter_lang_csv.hour","index":1,"aggr":"sum"}],"groups":[{"name":"twitter_lang_csv.lang","index":0,"aggr":"sum"}],"values":[{"name":"twitter_lang_csv.count","index":2,"aggr":"sum"}]},"helium":{}}},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TABLE","data":"twitter_lang_csv.lang\ttwitter_lang_csv.hour\ttwitter_lang_csv.count\npt\t21\t11422\nko\t0\t4418\npt\t23\t13032\nko\t4\t6049\nko\t12\t14186\npt\t5\t3148\npt\t11\t5933\npt\t12\t7057\npt\t20\t10281\nko\t2\t5134\nko\t7\t8115\nko\t22\t4368\nko\t3\t5872\npt\t1\t16230\nko\t9\t9780\nko\t21\t1859\npt\t4\t6035\npt\t14\t9363\npt\t18\t9195\npt\t22\t12160\npt\t15\t10678\nko\t23\t5692\npt\t10\t5026\npt\t17\t9569\nko\t19\t1543\npt\t16\t9887\nko\t11\t14311\npt\t8\t1781\npt\t9\t3808\npt\t3\t11223\nko\t16\t7711\nko\t10\t11631\npt\t19\t9404\nko\t5\t5883\nko\t15\t16618\npt\t6\t809\nko\t6\t3571\nko\t17\t3986\nko\t18\t2284\nko\t8\t8733\npt\t0\t14857\npt\t13\t8419\nko\t1\t5006\nko\t14\t16466\npt\t2\t15727\nko\t13\t16691\nko\t20\t1278\npt\t7\t1474\n"}]},"apps":[],"jobName":"paragraph_1553669999442_-1579362389","id":"20180320-135453_712665411","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45973"},{"text":"%md\n\n### Find the most retweeted users\n\nIn the next queries you will compute the list of the 50 most retweeted users.\n\nYou will first create the table __twitter_users__ and store it in __parquet__ format.\n\n```shell\n%jdbc(hive)\ncreate table CHANGEME\nstored as parquet\nas\nselect CHANGEME(json, '$.retweeted_status.user.screen_name') as name\nfrom CHANGEME\nwhere CHANGEME(json, '$.retweeted_status') is not null;\n```\n\nNext you will create the table of  the 50 most popular users in decreasing order of retweets for the day.\n\n```shell\n%jdbc(hive)\ncreate table CHANGEME.twitter_users_count\nrow format delimited\n    fields terminated by ','\n    escaped by '\"'\n    lines terminated by '\\n'\nstored as textfile\nselect name, count(*) as count\nfrom CHANGEME.twitter_users\ngroup by name\norder by count desc\nlimit 50;\n```\n\nNote that we have created the table in textfile format, and we have specified a row format as a CSV file. To wrap this exercise up, try to find this file in HDFS and use the __hdfs dfs -cat__ command to visualize it. You can then use __hdfs dfs -get__ and __scp__ or rsync to copy it on your laptop.\n","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"editOnDblClick":true,"language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>Find the most retweeted users</h3>\n<p>In the next queries you will compute the list of the 50 most retweeted users.</p>\n<p>You will first create the table <strong>twitter_users</strong> and store it in <strong>parquet</strong> format.</p>\n<pre><code class=\"shell\">%jdbc(hive)\ncreate table CHANGEME\nstored as parquet\nas\nselect CHANGEME(json, '$.retweeted_status.user.screen_name') as name\nfrom CHANGEME\nwhere CHANGEME(json, '$.retweeted_status') is not null;\n</code></pre>\n<p>Next you will create the table of  the 50 most popular users in decreasing order of retweets for the day.</p>\n<pre><code class=\"shell\">%jdbc(hive)\ncreate table CHANGEME.twitter_users_count\nrow format delimited\n    fields terminated by ','\n    escaped by '\"'\n    lines terminated by '\\n'\nstored as textfile\nselect name, count(*) as count\nfrom CHANGEME.twitter_users\ngroup by name\norder by count desc\nlimit 50;\n</code></pre>\n<p>Note that we have created the table in textfile format, and we have specified a row format as a CSV file. To wrap this exercise up, try to find this file in HDFS and use the <strong>hdfs dfs -cat</strong> command to visualize it. You can then use <strong>hdfs dfs -get</strong> and <strong>scp</strong> or rsync to copy it on your laptop.</p>\n"}]},"apps":[],"jobName":"paragraph_1553669999442_1875787745","id":"20180321-102100_1524832575","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45974"},{"text":"%jdbc(hive)\ncreate table gaspar.twitter_users\nstored as parquet\nas\nselect get_json_object(json, '$.retweeted_status.user.screen_name') as name\nfrom gaspar.twitter_one_day\nwhere get_json_object(json, '$.retweeted_status') is not null;","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"}]},"apps":[],"jobName":"paragraph_1553669999443_-279583058","id":"20180320-111048_1278675940","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45975"},{"text":"%jdbc(hive)\ncreate table gaspar.twitter_users_count\nrow format delimited\n    fields terminated by ','\n    escaped by '\"'\n    lines terminated by '\\n'\nstored as textfile\nas select name, count(*) as count\nfrom gaspar.twitter_users\ngroup by name\norder by count desc\nlimit 50;","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"editorSetting":{"editOnDblClick":false,"language":"sql","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/sql","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Query executed successfully. Affected rows : -1"}]},"apps":[],"jobName":"paragraph_1553669999444_702687569","id":"20180320-111112_142668305","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45976"},{"text":"%md\n### That's all, folks","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"tableHide":false,"editorSetting":{"editOnDblClick":true,"language":"markdown"},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h3>That's all, folks</h3>\n"}]},"apps":[],"jobName":"paragraph_1553669999445_1275666962","id":"20180320-143329_5934928","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45977"},{"text":"%md\n","user":"ebouille","dateUpdated":"2019-03-27T07:59:59+0100","config":{"editorSetting":{"editOnDblClick":true,"language":"markdown","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1553669999445_1125196831","id":"20180321-114758_916463376","dateCreated":"2019-03-27T07:59:59+0100","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:45978"}],"name":"/ebouille/week5-solutions","id":"2E7R9M7FS","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"jdbc:shared_process":[],"spark2:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}